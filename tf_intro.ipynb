{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Fundamentals\n",
    "\n",
    "## Calculating Gradients\n",
    "\n",
    "In a previous exercise, we practiced calculating partial derivatives on the following example:\n",
    "\n",
    "$$ f(x,y) = \\sqrt{x^2 + y^2}$$\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x} = \\frac{x}{\\sqrt{x^2 + y^2}}$$\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial y} = \\frac{y}{\\sqrt{x^2 + y^2}}$$\n",
    "\n",
    "### Question\n",
    "Take a second to use a calculator or a sheet of paper to calcuate the following:\n",
    "\n",
    "*   $\\displaystyle f(3, 4) = ??$\n",
    "    \n",
    "\n",
    "*   $ \\displaystyle \\frac{\\partial f(3, 4)}{\\partial x} = ??$\n",
    "    \n",
    "   \n",
    "*   $ \\displaystyle \\frac{\\partial f(3, 4)}{\\partial y} = ??$\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers:\n",
    "* \n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At its core, TensorFlow is a library for representing mathematical operations as graphical structures and automating the process of computing partial derivatives.  We can use it to write numpy-style mathematical operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def f(x, y):\n",
    "    return tf.sqrt(x**2 + y**2)\n",
    "    \n",
    "x = tf.Variable(3, dtype=tf.float32)\n",
    "y = tf.Variable(4, dtype=tf.float32)\n",
    "\n",
    "print(f(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More interestingly, we can use a `GradientTape` to record methematical operations for automatic differentiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x)\n",
    "    tape.watch(y)\n",
    "    fxy = f(x, y)\n",
    "    \n",
    "df_dx = tape.gradient(fxy, x)\n",
    "df_dy = tape.gradient(fxy, y)\n",
    "\n",
    "print(\"f(3, 4) = {:.5}\".format(fxy))\n",
    "print(\"df(3, 4)/dx = {:.5}\".format(df_dx))\n",
    "print(\"df(3, 4)/dy = {:.5}\".format(df_dy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the partial derivatives, we can minimize our function using gradient descent.  Use the cell below to find the x and y that minimize $ f(x,y) = \\sqrt{x^2 + y^2}$.  You many need to experiment with the learning rate and the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .01\n",
    "iterations = 10\n",
    "\n",
    "x = tf.Variable(3, dtype=tf.float32)\n",
    "y = tf.Variable(4, dtype=tf.float32)\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x)\n",
    "        tape.watch(y)\n",
    "        fxy = f(x, y)\n",
    "    \n",
    "    df_dx = tape.gradient(fxy, x)\n",
    "    df_dy = tape.gradient(fxy, y)\n",
    "    \n",
    "    x.assign(x - learning_rate * df_dx)\n",
    "    y.assign(y - learning_rate * df_dy)\n",
    "    print('current \"loss\": {}'.format(fxy))\n",
    "\n",
    "print(\"\\nx: {}\".format(x.numpy()))\n",
    "print(\"y: {}\".format(y.numpy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSets\n",
    "\n",
    "In machine learning it is often the case that training data is too large to fit in memory on a single machine.  We may also want to perform some pre-processing on the data as it is loaded.  The `tf.data.Dataset` class provides a standard interface of feeding data to a machine learning model.  `Dataset` objects act as Python generators. \n",
    "\n",
    "We can create a Dataset from a numpy array using the `from_tensor_slices` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Generate 6 random two-dimensional elements as column vectors:\n",
    "\n",
    "features = np.round(np.random.random((6, 2, 1)), 2)\n",
    "print(\"Numpy array of data:\\n\")\n",
    "print(features)\n",
    "  \n",
    "# Build a dataset:\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "\n",
    "# iterate over the elements in the dataset:\n",
    "\n",
    "print(\"\\nIterate over the corresponding Dataset:\\n\")\n",
    "for element in dataset:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batches\n",
    "\n",
    "It is usually more efficent to process data in *batches* than individually. Here is an example of Tensorflow code that multiplies each element in our data set by an appropriately sized weight vector and sums the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = tf.Variable(np.zeros((1,1)))\n",
    "weights = tf.Variable(np.random.random((2,1)))\n",
    "\n",
    "for element in dataset:\n",
    "    total = total + tf.matmul(tf.transpose(weights), element)\n",
    "    print(\"Total so far: {}\".format(total))\n",
    "\n",
    "print(\"\\nFinal Total: {}\".format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of processing one data element per iteration, w can batch the dataset and process k-operations per iteration.  Many TensorFlow operators are \"batch-aware\" and will recognize that the first dimension corrsponds to the batch.  Let's look at a batched version of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_batched = dataset.batch(2)\n",
    "for batch in dataset_batched:\n",
    "    print(\"Shape: {}\\n\".format(batch.shape))\n",
    "    print(\"Elements:\\n {}\\n\".format(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = tf.Variable(np.zeros((1, 1)))\n",
    "\n",
    "for batch in dataset_batched:\n",
    "    batch_of_products = tf.matmul(tf.transpose(weights), batch)\n",
    "    total = total + tf.reduce_sum(batch_of_products)\n",
    "    print(\"Total so far: {}\".format(total))\n",
    "\n",
    "print(\"\\nFinal Total: {}\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
