{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Fundamentals\n",
    "\n",
    "Learning Objectives:\n",
    "\n",
    "* Gain experience with low-level Tensorflow operations\n",
    "* Learn to use GradientTape to calculate partial derivatives and perform gradient descent\n",
    "* Learn about the tf.data.Dataset class, including batching\n",
    "\n",
    "## Calculating Gradients\n",
    "\n",
    "In a previous exercise, we practiced calculating partial derivatives on the following example:\n",
    "\n",
    "$$ f(x,y) = \\sqrt{x^2 + y^2}$$\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x} = \\frac{x}{\\sqrt{x^2 + y^2}}$$\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial y} = \\frac{y}{\\sqrt{x^2 + y^2}}$$\n",
    "\n",
    "### Question\n",
    "Take a second to calcuate the following by hand:\n",
    "\n",
    "*   $\\displaystyle f(3, 4) = ??$\n",
    "    \n",
    "\n",
    "*   $ \\displaystyle \\frac{\\partial f(3, 4)}{\\partial x} = ??$\n",
    "    \n",
    "   \n",
    "*   $ \\displaystyle \\frac{\\partial f(3, 4)}{\\partial y} = ??$\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers:\n",
    "* \n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At its core, TensorFlow is a library for representing mathematical operations as graphical structures and automating the process of computing partial derivatives.  We can use TensorFlow to write numpy-style mathematical operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def f(x, y):\n",
    "    return tf.sqrt(x**2 + y**2)\n",
    "    \n",
    "x = tf.Variable(3, dtype=tf.float32)\n",
    "y = tf.Variable(4, dtype=tf.float32)\n",
    "\n",
    "print(f(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More interestingly, we can use a `GradientTape` to record mathematical operations for automatic differentiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(3, 4) = 5.0\n",
      "df(3, 4)/dx = 0.6\n",
      "df(3, 4)/dy = 0.8\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x)\n",
    "    tape.watch(y)\n",
    "    fxy = f(x, y)\n",
    "    \n",
    "df_dx = tape.gradient(fxy, x)\n",
    "df_dy = tape.gradient(fxy, y)\n",
    "\n",
    "print(\"f(3, 4) = {:.5}\".format(fxy))\n",
    "print(\"df(3, 4)/dx = {:.5}\".format(df_dx))\n",
    "print(\"df(3, 4)/dy = {:.5}\".format(df_dy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the partial derivatives, we can minimize our function using gradient descent.  Use the cell below to find the x and y that minimize $ f(x,y) = \\sqrt{x^2 + y^2}$.  Adjust the learning rate and the number of iterations (*not* the starting x and y values) until the code converges to something close to the minimum value for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current \"loss\": 5.0\n",
      "current \"loss\": 4.990000247955322\n",
      "current \"loss\": 4.980000019073486\n",
      "current \"loss\": 4.970000267028809\n",
      "current \"loss\": 4.960000038146973\n",
      "current \"loss\": 4.950000286102295\n",
      "current \"loss\": 4.940000057220459\n",
      "current \"loss\": 4.930000305175781\n",
      "current \"loss\": 4.9200005531311035\n",
      "current \"loss\": 4.910000801086426\n",
      "\n",
      "x: 2.939999580383301\n",
      "y: 3.9200010299682617\n"
     ]
    }
   ],
   "source": [
    "learning_rate = .01\n",
    "iterations = 10\n",
    "\n",
    "x = tf.Variable(3, dtype=tf.float32)\n",
    "y = tf.Variable(4, dtype=tf.float32)\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x)\n",
    "        tape.watch(y)\n",
    "        fxy = f(x, y)\n",
    "    \n",
    "    print('current \"loss\": {}'.format(fxy))\n",
    "    \n",
    "    df_dx = tape.gradient(fxy, x)\n",
    "    df_dy = tape.gradient(fxy, y)\n",
    "    \n",
    "    x = x - learning_rate * df_dx\n",
    "    y = y - learning_rate * df_dy\n",
    "    \n",
    "\n",
    "print(\"\\nx: {}\".format(x.numpy()))\n",
    "print(\"y: {}\".format(y.numpy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "* What learning rate and iteration count did you settle on? \n",
    "* Where does this this have its minimum? (Note that this is a case where we don't *need* to use gradient descent to find the solution. You should be able to predict the minimum value without executing the code above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers:\n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSets\n",
    "\n",
    "In machine learning it is often the case that training data is too large to fit in memory on a single machine.  We may also want to perform some pre-processing on the data as it is loaded.  The `tf.data.Dataset` class provides a standard interface of feeding data to a machine learning model.  `Dataset` objects act as Python generators. \n",
    "\n",
    "We can create a Dataset from a numpy array using the `from_tensor_slices` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array of data:\n",
      "\n",
      "[[[1.  ]\n",
      "  [0.77]]\n",
      "\n",
      " [[0.89]\n",
      "  [0.87]]\n",
      "\n",
      " [[0.03]\n",
      "  [0.6 ]]\n",
      "\n",
      " [[0.56]\n",
      "  [0.72]]\n",
      "\n",
      " [[0.  ]\n",
      "  [0.48]]\n",
      "\n",
      " [[0.2 ]\n",
      "  [0.82]]]\n",
      "\n",
      "Iterate over the corresponding Dataset:\n",
      "\n",
      "tf.Tensor(\n",
      "[[1.  ]\n",
      " [0.77]], shape=(2, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0.89]\n",
      " [0.87]], shape=(2, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0.03]\n",
      " [0.6 ]], shape=(2, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0.56]\n",
      " [0.72]], shape=(2, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0.  ]\n",
      " [0.48]], shape=(2, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0.2 ]\n",
      " [0.82]], shape=(2, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Generate 6 random two-dimensional elements as column vectors:\n",
    "\n",
    "features = np.round(np.random.random((6, 2, 1)), 2)\n",
    "print(\"Numpy array of data:\\n\")\n",
    "print(features)\n",
    "  \n",
    "# Build a dataset:\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "\n",
    "# iterate over the elements in the dataset:\n",
    "\n",
    "print(\"\\nIterate over the corresponding Dataset:\\n\")\n",
    "for element in dataset:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batches\n",
    "\n",
    "It is usually more efficent to process data in *batches* than individually. Here is an example of Tensorflow code that multiplies each element in our data set by an appropriately sized weight vector and sums the result.  In this example each element is processed individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total so far: [[1.18588664]]\n",
      "Total so far: [[2.30891774]]\n",
      "Total so far: [[2.55561414]]\n",
      "Total so far: [[3.32539864]]\n",
      "Total so far: [[3.50105733]]\n",
      "Total so far: [[3.9819611]]\n",
      "\n",
      "Final Total: [[3.9819611]]\n"
     ]
    }
   ],
   "source": [
    "total = tf.Variable(np.zeros((1,1)))\n",
    "weights = tf.Variable(np.random.random((2,1)))\n",
    "\n",
    "for element in dataset:\n",
    "    total = total + tf.matmul(tf.transpose(weights), element)\n",
    "    print(\"Total so far: {}\".format(total))\n",
    "\n",
    "print(\"\\nFinal Total: {}\".format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of processing one data element per iteration, we can batch the dataset and process multiple elements per iteration.  Many TensorFlow operators, including `tf.matmul`, are \"batch-aware\" and will recognize that the first dimension corresponds to the batch.  Let's look at a batched version of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2, 2, 1)\n",
      "\n",
      "Elements:\n",
      " [[[1.  ]\n",
      "  [0.77]]\n",
      "\n",
      " [[0.89]\n",
      "  [0.87]]]\n",
      "\n",
      "Shape: (2, 2, 1)\n",
      "\n",
      "Elements:\n",
      " [[[0.03]\n",
      "  [0.6 ]]\n",
      "\n",
      " [[0.56]\n",
      "  [0.72]]]\n",
      "\n",
      "Shape: (2, 2, 1)\n",
      "\n",
      "Elements:\n",
      " [[[0.  ]\n",
      "  [0.48]]\n",
      "\n",
      " [[0.2 ]\n",
      "  [0.82]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_batched = dataset.batch(2)\n",
    "for batch in dataset_batched:\n",
    "    print(\"Shape: {}\\n\".format(batch.shape))\n",
    "    print(\"Elements:\\n {}\\n\".format(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total so far: [[2.30891774]]\n",
      "Total so far: [[3.32539864]]\n",
      "Total so far: [[3.9819611]]\n",
      "\n",
      "Final Total: [[3.9819611]]\n"
     ]
    }
   ],
   "source": [
    "total = tf.Variable(np.zeros((1, 1)))\n",
    "\n",
    "for batch in dataset_batched:\n",
    "    batch_of_products = tf.matmul(tf.transpose(weights), batch)\n",
    "    total = total + tf.reduce_sum(batch_of_products)\n",
    "    print(\"Total so far: {}\".format(total))\n",
    "\n",
    "print(\"\\nFinal Total: {}\".format(total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
